import pandas as pd
import re
import jieba
import numpy as np

def clean_text(str):
    pattern = re.compile(u'['u'\U0001F300-\U0001F64F' u'\U0001F680-\U0001F6FF'u'\u2600-\u2B55]+')
    str = pattern.sub("",str)
    str = re.sub("[=ã€Šã€‹!/.,ã€‚ï¼Œã€ï¼ â€œâ€™ ï¼šÂ·ğŸ˜„ <>ï¼‰\u200bï¼ˆa-zA-Z0-9/\r\n, ]",'',str)
    if str != "" and len(str)>3:
        return str

def simliarity_cal(str1,str2):
    vec1,vec2 = get_word_vector(str1,str2)
    return cos_dist(vec1,vec2)


def get_word_vector(s1, s2):
    # åˆ†è¯
    cut1 = jieba.cut(s1)
    cut2 = jieba.cut(s2)
    list_word1 = (','.join(cut1)).split(',')
    list_word2 = (','.join(cut2)).split(',')
    # åˆ—å‡ºæ‰€æœ‰çš„è¯,å–å¹¶é›†
    key_word = list(set(list_word1 + list_word2))
    # ç»™å®šå½¢çŠ¶å’Œç±»å‹çš„ç”¨0å¡«å……çš„çŸ©é˜µå­˜å‚¨å‘é‡
    word_vector1 = np.zeros(len(key_word))
    word_vector2 = np.zeros(len(key_word))
    # è®¡ç®—è¯é¢‘
    # ä¾æ¬¡ç¡®å®šå‘é‡çš„æ¯ä¸ªä½ç½®çš„å€¼
    for i in range(len(key_word)):
        # éå†key_wordä¸­æ¯ä¸ªè¯åœ¨å¥å­ä¸­çš„å‡ºç°æ¬¡æ•°
        for j in range(len(list_word1)):
            if key_word[i] == list_word1[j]:
                word_vector1[i] += 1
        for k in range(len(list_word2)):
            if key_word[i] == list_word2[k]:
                word_vector2[i] += 1

    return word_vector1, word_vector2

def cos_dist(vec1,vec2):
    dist1=float(np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2)))
    return dist1

def str_cal(str):
    text = pd.read_excel("static//word_dict.xlsx")
    text = text.dropna()
    text = text['comment']
    word_dict = [clean_text(line) for line in text]
    word_dict = list(filter(None, word_dict))
    max_score = 0
    sim_str = ""
    for item in word_dict:
        score = simliarity_cal(str,item)
        if score>max_score:
            max_score = score
            sim_str = item
    return "è¯„è®ºä¸è¯­æ–™åº“çš„ç›¸ä¼¼åº¦ä¸º{}%ï¼Œæœ€ç›¸ä¼¼çš„å¥å­ä¸º:{}".format(round(max_score*100),sim_str)
